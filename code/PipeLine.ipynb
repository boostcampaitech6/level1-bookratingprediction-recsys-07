{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages and install pip\n",
    "### 본 노트북은 다음과 같은 구조일 때 동작합니다\n",
    "```\n",
    "   upper\n",
    "     ├─ /code\n",
    "     |    ├─ /data\n",
    "     |    ├─ /src\n",
    "     |    ├─ /submit\n",
    "     |    ├─ ... \n",
    "     |    ├─ PipeLine.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#torch 안깔려 있으면, 까셔야 합니다 ..!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r ../code/requirement.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r ../code/requirement.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from -r ../code/requirement.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r ../code/requirement.txt (line 4)) (4.35.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r ../code/requirement.txt (line 2)) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r ../code/requirement.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r ../code/requirement.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->-r ../code/requirement.txt (line 3)) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->-r ../code/requirement.txt (line 3)) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->-r ../code/requirement.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->-r ../code/requirement.txt (line 4)) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->-r ../code/requirement.txt (line 4)) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r ../code/requirement.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (2023.11.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting easydict\n",
      "  Using cached easydict-1.11.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for easydict: filename=easydict-1.11-py3-none-any.whl size=6660 sha256=d557359f241ca82b3b8ba8e566c751b0f3989010abce3671bd9f61f536ccde8d\n",
      "  Stored in directory: /data/ephemeral/home/.cache/pip/wheels/58/05/80/2adaebf497dacf51a0267ec07b3451ce91b596e2b9502d67d6\n",
      "Successfully built easydict\n",
      "Installing collected packages: easydict\n",
      "Successfully installed easydict-1.11\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -r ../code/requirement.txt\n",
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import easydict\n",
    "from src.utils import Logger, Setting, models_load\n",
    "from src.data import context_data_load, context_data_split, context_data_loader\n",
    "from src.data import dl_data_load, dl_data_split, dl_data_loader\n",
    "from src.data import image_data_load, image_data_split, image_data_loader\n",
    "from src.data import text_data_load, text_data_split, text_data_loader\n",
    "from src.train import train, test\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    'data_path': './data/',  # Data path 설정\n",
    "    'saved_model_path': './saved_models',  # Saved Model path 설정\n",
    "    'model': \"FM\",  # 학습 및 예측할 모델 선택 (None으로 초기화, 사용 전에 설정 필요)\n",
    "    'data_shuffle': True,  # 데이터 셔플 여부 조정\n",
    "    'test_size': 0.2,  # Train/Valid split 비율 조정\n",
    "    'seed': 42,  # Seed 값 조정\n",
    "    'use_best_model': True,  # 검증 성능이 가장 좋은 모델 사용 여부 설정\n",
    "\n",
    "    # TRAINING OPTION\n",
    "    'batch_size': 1024,  # Batch size 조정\n",
    "    'epochs': 10,  # Epoch 수 조정\n",
    "    'lr': 1e-3,  # Learning Rate 조정\n",
    "    'loss_fn': 'RMSE',  # 손실 함수 변경 (MSE 또는 RMSE)\n",
    "    'optimizer': 'ADAM',  # 최적화 함수 변경 (SGD 또는 ADAM)\n",
    "    'weight_decay': 1e-6,  # Adam optimizer에서 정규화에 사용하는 값 조정\n",
    "\n",
    "    # GPU\n",
    "    'device': 'cuda',  # 학습에 사용할 Device 조정\n",
    "\n",
    "    # FM, FFM, NCF, WDN, DCN Common OPTION\n",
    "    'embed_dim': 16,  # FM, FFM, NCF, WDN, DCN에서 embedding시킬 차원 조정\n",
    "    'dropout': 0.2,  # NCF, WDN, DCN에서 Dropout rate 조정\n",
    "    'mlp_dims': (16, 16),  # NCF, WDN, DCN에서 MLP Network의 차원 조정\n",
    "\n",
    "    # DCN\n",
    "    'num_layers': 3,  # Cross Network의 레이어 수 조정\n",
    "\n",
    "    # CNN_FM\n",
    "    'cnn_embed_dim': 64,  # CNN_FM에서 user와 item에 대한 embedding시킬 차원 조정\n",
    "    'cnn_latent_dim': 12,  # CNN_FM에서 user/item/image에 대한 latent 차원 조정\n",
    "\n",
    "    # DeepCoNN\n",
    "    'vector_create': False,  # DEEP_CONN에서 text vector 생성 여부 조정 (최초 학습에만 True로 설정)\n",
    "    'deepconn_embed_dim': 32,  # DEEP_CONN에서 user와 item에 대한 embedding시킬 차원 조정\n",
    "    'deepconn_latent_dim': 10,  # DEEP_CONN에서 user/item/image에 대한 latent 차원 조정\n",
    "    'conv_1d_out_dim': 50,  # DEEP_CONN에서 1D conv의 출력 크기 조정\n",
    "    'kernel_size': 3,  # DEEP_CONN에서 1D conv의 kernel 크기 조정\n",
    "    'word_dim': 768,  # DEEP_CONN에서 1D conv의 입력 크기 조정\n",
    "    'out_dim': 32  # DEEP_CONN에서 1D conv의 출력 크기 조정\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Setting.seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FM Load Data ---------------\n"
     ]
    }
   ],
   "source": [
    "print(f'--------------- {args.model} Load Data ---------------')\n",
    "if args.model in ('FM', 'FFM'):\n",
    "    data = context_data_load(args)\n",
    "elif args.model in ('NCF', 'WDN', 'DCN'):\n",
    "    data = dl_data_load(args)\n",
    "elif args.model == 'CNN_FM':\n",
    "    data = image_data_load(args)\n",
    "elif args.model == 'DeepCoNN':\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    data = text_data_load(args)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FM Train/Valid Split ---------------\n"
     ]
    }
   ],
   "source": [
    "######################## Train/Valid Split\n",
    "print(f'--------------- {args.model} Train/Valid Split ---------------')\n",
    "if args.model in ('FM', 'FFM'):\n",
    "    data = context_data_split(args, data)\n",
    "    data = context_data_loader(args, data)\n",
    "\n",
    "elif args.model in ('NCF', 'WDN', 'DCN'):\n",
    "    data = dl_data_split(args, data)\n",
    "    data = dl_data_loader(args, data)\n",
    "\n",
    "elif args.model=='CNN_FM':\n",
    "    data = image_data_split(args, data)\n",
    "    data = image_data_loader(args, data)\n",
    "\n",
    "elif args.model=='DeepCoNN':\n",
    "    data = text_data_split(args, data)\n",
    "    data = text_data_loader(args, data)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logs settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Setting for Log\n",
    "setting = Setting()\n",
    "\n",
    "log_path = setting.get_log_path(args)\n",
    "setting.make_dir(log_path)\n",
    "\n",
    "logger = Logger(args, log_path)\n",
    "logger.save_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model (FM 모델을 예시로 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# factorization을 통해 얻은 feature를 embedding 합니다.\n",
    "class FeaturesEmbedding(nn.Module):\n",
    "    def __init__(self, field_dims: np.ndarray, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "# FM모델 등에서 활용되는 선형 결합 부분을 정의합니다.\n",
    "class FeaturesLinear(nn.Module):\n",
    "    def __init__(self, field_dims: np.ndarray, output_dim: int=1):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias\n",
    "\n",
    "\n",
    "# feature 사이의 상호작용을 효율적으로 계산합니다.\n",
    "class FactorizationMachine(nn.Module):\n",
    "    def __init__(self, reduce_sum:bool=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
    "        return 0.5 * ix\n",
    "\n",
    "# FM 모델을 구현합니다.\n",
    "class FactorizationMachineModel(nn.Module):\n",
    "    def __init__(self, args, data):\n",
    "        super().__init__()\n",
    "        self.field_dims = data['field_dims']\n",
    "        self.embedding = FeaturesEmbedding(self.field_dims, args.embed_dim)\n",
    "        self.linear = FeaturesLinear(self.field_dims)\n",
    "        self.fm = FactorizationMachine(reduce_sum=True)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.linear(x) + self.fm(self.embedding(x))\n",
    "        # return torch.sigmoid(x.squeeze(1))\n",
    "        return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# feature 사이의 상호작용을 효율적으로 계산합니다.\n",
    "class FactorizationMachine(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.v = nn.Parameter(torch.rand(input_dim, latent_dim), requires_grad = True)\n",
    "        self.linear = nn.Linear(input_dim, 1, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear = self.linear(x)\n",
    "        square_of_sum = torch.mm(x, self.v) ** 2\n",
    "        sum_of_square = torch.mm(x ** 2, self.v ** 2)\n",
    "        pair_interactions = torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n",
    "        output = linear + (0.5 * pair_interactions)\n",
    "        return output\n",
    "\n",
    "\n",
    "# factorization을 통해 얻은 feature를 embedding 합니다.\n",
    "class FeaturesEmbedding(nn.Module):\n",
    "    def __init__(self, field_dims: np.ndarray, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "# 텍스트 특징 추출을 위한 기초적인 CNN 1D Layer를 정의합니다.\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, word_dim, out_dim, kernel_size, conv_1d_out_dim):\n",
    "        super(CNN_1D, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                                nn.Conv1d(\n",
    "                                        in_channels=word_dim,\n",
    "                                        out_channels=out_dim,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        padding=(kernel_size - 1) // 2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(kernel_size, 1)),\n",
    "                                nn.Dropout(p=0.5)\n",
    "                                )\n",
    "        self.linear = nn.Sequential(\n",
    "                                    nn.Linear(int(out_dim/kernel_size), conv_1d_out_dim),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(p=0.5))\n",
    "\n",
    "\n",
    "    def forward(self, vec):\n",
    "        output = self.conv(vec)\n",
    "        output = self.linear(output.reshape(-1, output.size(1)))\n",
    "        return output\n",
    "\n",
    "\n",
    "# 기존 유저/상품 벡터와 유저/상품 리뷰 벡터를 결합하여 FM으로 학습하는 모델을 구현합니다.\n",
    "class DeepCoNN(nn.Module):\n",
    "    def __init__(self, args, data):\n",
    "        super(DeepCoNN, self).__init__()\n",
    "        self.field_dims = np.array([len(data['user2idx']), len(data['isbn2idx'])], dtype=np.uint32)\n",
    "        self.embedding = FeaturesEmbedding(self.field_dims, args.deepconn_embed_dim)\n",
    "        self.cnn_u = CNN_1D(\n",
    "                             word_dim=args.word_dim,\n",
    "                             out_dim=args.out_dim,\n",
    "                             kernel_size=args.kernel_size,\n",
    "                             conv_1d_out_dim=args.conv_1d_out_dim,\n",
    "                            )\n",
    "        self.cnn_i = CNN_1D(\n",
    "                             word_dim=args.word_dim,\n",
    "                             out_dim=args.out_dim,\n",
    "                             kernel_size=args.kernel_size,\n",
    "                             conv_1d_out_dim=args.conv_1d_out_dim,\n",
    "                            )\n",
    "        self.fm = FactorizationMachine(\n",
    "                                        input_dim=(args.conv_1d_out_dim * 2) + (args.deepconn_embed_dim*len(self.field_dims)),\n",
    "                                        latent_dim=args.deepconn_latent_dim,\n",
    "                                        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_isbn_vector, user_text_vector, item_text_vector = x[0], x[1], x[2]\n",
    "        user_isbn_feature = self.embedding(user_isbn_vector)\n",
    "        user_text_feature = self.cnn_u(user_text_vector)\n",
    "        item_text_feature = self.cnn_i(item_text_vector)\n",
    "        feature_vector = torch.cat([\n",
    "                                    user_isbn_feature.view(-1, user_isbn_feature.size(1) * user_isbn_feature.size(2)),\n",
    "                                    user_text_feature,\n",
    "                                    item_text_feature\n",
    "                                    ], dim=1)\n",
    "        output = self.fm(feature_vector)\n",
    "        return output.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- INIT FM ---------------\n"
     ]
    }
   ],
   "source": [
    "######################## Model\n",
    "print(f'--------------- INIT {args.model} ---------------')\n",
    "model = DeepCoNN(args, data).to(args.device) #이부분수정하면됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RMSEloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.eps = 1e-6\n",
    "    def forward(self, x, y):\n",
    "        criterion = MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y)+self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(args, model, dataloader, logger, setting):\n\u001b[1;32m      3\u001b[0m     minimum_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m999999999\u001b[39m\n",
      "Cell \u001b[0;32mIn[25], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, model, dataloader, logger, setting)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y\u001b[38;5;241m.\u001b[39mfloat(), y_hat)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 89\u001b[0m, in \u001b[0;36mDeepCoNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     88\u001b[0m     user_isbn_vector, user_text_vector, item_text_vector \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m], x[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 89\u001b[0m     user_isbn_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_isbn_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     user_text_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_u(user_text_vector)\n\u001b[1;32m     91\u001b[0m     item_text_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_i(item_text_vector)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 33\u001b[0m, in \u001b[0;36mFeaturesEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffsets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model = train(args, model, data, logger, setting)\n",
    "def train(args, model, dataloader, logger, setting):\n",
    "    minimum_loss = 999999999\n",
    "    if args.loss_fn == 'MSE':\n",
    "        loss_fn = MSELoss()\n",
    "    elif args.loss_fn == 'RMSE':\n",
    "        loss_fn = RMSELoss()\n",
    "    else:\n",
    "        pass\n",
    "    if args.optimizer == 'SGD':\n",
    "        optimizer = SGD(model.parameters(), lr=args.lr)\n",
    "    elif args.optimizer == 'ADAM':\n",
    "        optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(args.epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch = 0\n",
    "\n",
    "        for idx, data in enumerate(dataloader['train_dataloader']):\n",
    "            if args.model == 'CNN_FM':\n",
    "                x, y = [data['user_isbn_vector'].to(args.device), data['img_vector'].to(args.device)], data['label'].to(args.device)\n",
    "            elif args.model == 'DeepCoNN':\n",
    "                x, y = [data['user_isbn_vector'].to(args.device), data['user_summary_merge_vector'].to(args.device), data['item_summary_vector'].to(args.device)], data['label'].to(args.device)\n",
    "            else:\n",
    "                x, y = data[0].to(args.device), data[1].to(args.device)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y.float(), y_hat)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            batch +=1\n",
    "        valid_loss = valid(args, model, dataloader, loss_fn)\n",
    "        print(f'Epoch: {epoch+1}, Train_loss: {total_loss/batch:.3f}, valid_loss: {valid_loss:.3f}')\n",
    "        logger.log(epoch=epoch+1, train_loss=total_loss/batch, valid_loss=valid_loss)\n",
    "        if minimum_loss > valid_loss:\n",
    "            minimum_loss = valid_loss\n",
    "            os.makedirs(args.saved_model_path, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f'{args.saved_model_path}/{setting.save_time}_{args.model}_model.pt')\n",
    "    logger.close()\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid(args, model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch = 0\n",
    "\n",
    "    for idx, data in enumerate(dataloader['valid_dataloader']):\n",
    "        if args.model == 'CNN_FM':\n",
    "            x, y = [data['user_isbn_vector'].to(args.device), data['img_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        elif args.model == 'DeepCoNN':\n",
    "            x, y = [data['user_isbn_vector'].to(args.device), data['user_summary_merge_vector'].to(args.device), data['item_summary_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        else:\n",
    "            x, y = data[0].to(args.device), data[1].to(args.device)\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y.float(), y_hat)\n",
    "        total_loss += loss.item()\n",
    "        batch +=1\n",
    "    valid_loss = total_loss/batch\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "def test(args, model, dataloader, setting):\n",
    "    predicts = list()\n",
    "    if args.use_best_model == True:\n",
    "        model.load_state_dict(torch.load(f'./saved_models/{setting.save_time}_{args.model}_model.pt'))\n",
    "    else:\n",
    "        pass\n",
    "    model.eval()\n",
    "\n",
    "    for idx, data in enumerate(dataloader['test_dataloader']):\n",
    "        if args.model == 'CNN_FM':\n",
    "            x, _ = [data['user_isbn_vector'].to(args.device), data['img_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        elif args.model == 'DeepCoNN':\n",
    "            x, _ = [data['user_isbn_vector'].to(args.device), data['user_summary_merge_vector'].to(args.device), data['item_summary_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        else:\n",
    "            x = data[0].to(args.device)\n",
    "        y_hat = model(x)\n",
    "        predicts.extend(y_hat.tolist())\n",
    "    return predicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FM PREDICT ---------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######################## INFERENCE\n",
    "print(f'--------------- {args.model} PREDICT ---------------')\n",
    "predicts = test(args, model, data, setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- SAVE FM PREDICT ---------------\n"
     ]
    }
   ],
   "source": [
    "######################## SAVE PREDICT\n",
    "print(f'--------------- SAVE {args.model} PREDICT ---------------')\n",
    "submission = pd.read_csv(args.data_path + 'sample_submission.csv')\n",
    "if args.model in ('FM', 'FFM', 'NCF', 'WDN', 'DCN', 'CNN_FM', 'DeepCoNN'):\n",
    "    submission['rating'] = predicts\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.prefix, sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답안 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = setting.get_submit_filename(args)\n",
    "submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
