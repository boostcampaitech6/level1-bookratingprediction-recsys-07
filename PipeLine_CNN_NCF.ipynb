{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages and install pip\n",
    "### 본 노트북은 다음과 같은 구조일 때 동작합니다\n",
    "```\n",
    "   upper\n",
    "     ├─ /code\n",
    "     |    ├─ /data\n",
    "     |    ├─ /src\n",
    "     |    ├─ /submit\n",
    "     |    ├─ ... \n",
    "     |    ├─ PipeLine.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (23.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#torch 안깔려 있으면, 까셔야 합니다 ..!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from -r ../code/requirement.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from -r ../code/requirement.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: nltk in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from -r ../code/requirement.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: transformers in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from -r ../code/requirement.txt (line 4)) (4.36.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from pandas->-r ../code/requirement.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from scikit-learn->-r ../code/requirement.txt (line 2)) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from scikit-learn->-r ../code/requirement.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from scikit-learn->-r ../code/requirement.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: click in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from nltk->-r ../code/requirement.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from nltk->-r ../code/requirement.txt (line 3)) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from nltk->-r ../code/requirement.txt (line 3)) (4.66.1)\n",
      "Requirement already satisfied: filelock in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: requests in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from transformers->-r ../code/requirement.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->-r ../code/requirement.txt (line 4)) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->-r ../code/requirement.txt (line 4)) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->-r ../code/requirement.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (from requests->transformers->-r ../code/requirement.txt (line 4)) (2023.11.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: easydict in /data/ephemeral/home/miniconda3/envs/level_1/lib/python3.8/site-packages (1.11)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -r ../code/requirement.txt\n",
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import easydict\n",
    "from src.utils import Logger, Setting, models_load\n",
    "from src.data import context_data_load, context_data_split, context_data_loader\n",
    "from src.data import dl_data_load, dl_data_split, dl_data_loader\n",
    "from src.data import image_data_load, image_data_split, image_data_loader\n",
    "from src.data import text_data_load, text_data_split, text_data_loader\n",
    "from src.train import train, test\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    'data_path': './data/',  # Data path 설정\n",
    "    'saved_model_path': './saved_models',  # Saved Model path 설정\n",
    "    'model': 'CNN_NCF',  # 학습 및 예측할 모델 선택 (None으로 초기화, 사용 전에 설정 필요)\n",
    "    'data_shuffle': True,  # 데이터 셔플 여부 조정\n",
    "    'test_size': 0.2,  # Train/Valid split 비율 조정\n",
    "    'seed': 42,  # Seed 값 조정\n",
    "    'use_best_model': True,  # 검증 성능이 가장 좋은 모델 사용 여부 설정\n",
    "\n",
    "    # TRAINING OPTION\n",
    "    'batch_size': 1024,  # Batch size 조정\n",
    "    'epochs': 10,  # Epoch 수 조정\n",
    "    'lr': 1e-3,  # Learning Rate 조정\n",
    "    'loss_fn': 'RMSE',  # 손실 함수 변경 (MSE 또는 RMSE)\n",
    "    'optimizer': 'ADAM',  # 최적화 함수 변경 (SGD 또는 ADAM)\n",
    "    'weight_decay': 1e-6,  # Adam optimizer에서 정규화에 사용하는 값 조정\n",
    "\n",
    "    # GPU\n",
    "    'device': 'cuda',  # 학습에 사용할 Device 조정\n",
    "\n",
    "    # FM, FFM, NCF, WDN, DCN Common OPTION\n",
    "    'embed_dim': 16,  # FM, FFM, NCF, WDN, DCN에서 embedding시킬 차원 조정\n",
    "    'dropout': 0.2,  # NCF, WDN, DCN에서 Dropout rate 조정\n",
    "    'mlp_dims': (16, 16),  # NCF, WDN, DCN에서 MLP Network의 차원 조정\n",
    "\n",
    "    # DCN\n",
    "    'num_layers': 3,  # Cross Network의 레이어 수 조정\n",
    "\n",
    "    # CNN_FM\n",
    "    'cnn_embed_dim': 64,  # CNN_FM에서 user와 item에 대한 embedding시킬 차원 조정\n",
    "    'cnn_latent_dim': 12,  # CNN_FM에서 user/item/image에 대한 latent 차원 조정\n",
    "\n",
    "    # DeepCoNN\n",
    "    'vector_create': False,  # DEEP_CONN에서 text vector 생성 여부 조정 (최초 학습에만 True로 설정)\n",
    "    'deepconn_embed_dim': 32,  # DEEP_CONN에서 user와 item에 대한 embedding시킬 차원 조정\n",
    "    'deepconn_latent_dim': 10,  # DEEP_CONN에서 user/item/image에 대한 latent 차원 조정\n",
    "    'conv_1d_out_dim': 50,  # DEEP_CONN에서 1D conv의 출력 크기 조정\n",
    "    'kernel_size': 3,  # DEEP_CONN에서 1D conv의 kernel 크기 조정\n",
    "    'word_dim': 768,  # DEEP_CONN에서 1D conv의 입력 크기 조정\n",
    "    'out_dim': 32  # DEEP_CONN에서 1D conv의 출력 크기 조정\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Setting.seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- CNN_NCF Load Data ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "129777it [00:55, 2355.82it/s]\n",
      "52000it [00:21, 2370.05it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f'--------------- {args.model} Load Data ---------------')\n",
    "if args.model in ('FM', 'FFM'):\n",
    "    data = context_data_load(args)\n",
    "elif args.model in ('NCF', 'WDN', 'DCN'):\n",
    "    data = dl_data_load(args)\n",
    "elif args.model in ('CNN_FM', 'CNN_NCF'):\n",
    "    data = image_data_load(args)\n",
    "elif args.model == 'DeepCoNN':\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    data = text_data_load(args)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- CNN_NCF Train/Valid Split ---------------\n"
     ]
    }
   ],
   "source": [
    "######################## Train/Valid Split\n",
    "print(f'--------------- {args.model} Train/Valid Split ---------------')\n",
    "if args.model in ('FM', 'FFM'):\n",
    "    data = context_data_split(args, data)\n",
    "    data = context_data_loader(args, data)\n",
    "\n",
    "elif args.model in ('NCF', 'WDN', 'DCN'):\n",
    "    data = dl_data_split(args, data)\n",
    "    data = dl_data_loader(args, data)\n",
    "\n",
    "elif args.model in ('CNN_FM', 'CNN_NCF'):\n",
    "    data = image_data_split(args, data)\n",
    "    data = image_data_loader(args, data)\n",
    "\n",
    "elif args.model=='DeepCoNN':\n",
    "    data = text_data_split(args, data)\n",
    "    data = text_data_loader(args, data)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logs settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Setting for Log\n",
    "setting = Setting()\n",
    "\n",
    "log_path = setting.get_log_path(args)\n",
    "setting.make_dir(log_path)\n",
    "\n",
    "logger = Logger(args, log_path)\n",
    "logger.save_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model (FM 모델을 예시로 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# factorization을 통해 얻은 feature를 embedding 합니다.\n",
    "class FeaturesEmbedding(nn.Module):\n",
    "    def __init__(self, field_dims: np.ndarray, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "# NCF 모델은 MLP와 GMF를 합하여 최종 결과를 도출합니다.\n",
    "# MLP을 구현합니다.\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for embed_dim in embed_dims:\n",
    "            layers.append(torch.nn.Linear(input_dim, embed_dim))\n",
    "            layers.append(torch.nn.BatchNorm1d(embed_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(p=dropout))\n",
    "            input_dim = embed_dim\n",
    "        if output_layer:\n",
    "            layers.append(torch.nn.Linear(input_dim, 1))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "# 이미지 특징 추출을 위한 기초적인 CNN Layer를 정의합니다.\n",
    "class CNN_Base(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(CNN_Base, self).__init__()\n",
    "        self.cnn_layer = nn.Sequential(\n",
    "                                        nn.Conv2d(3, 6, kernel_size=3, stride=2, padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                        nn.Conv2d(6, 12, kernel_size=3, stride=2, padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                        )\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layer(x)\n",
    "        x = x.view(-1, 12 * 1 * 1)\n",
    "        return x\n",
    "\n",
    "# user와 item의 latent factor를 활용하여 GMF를 구현합니다.\n",
    "# 그리고 MLP결과와 concat하여 NCF 모델을 구현하고 최종 결과를 도출합니다.\n",
    "class CNN_NCF(nn.Module):\n",
    "    def __init__(self, args, data):\n",
    "        super().__init__()\n",
    "        self.field_dims = data['field_dims']\n",
    "        self.user_field_idx = np.array((0, ), dtype=np.int32)\n",
    "        self.item_field_idx = np.array((1, ), dtype=np.int32)\n",
    "        self.embedding = FeaturesEmbedding(self.field_dims, args.embed_dim)\n",
    "        self.embed_output_dim = len(self.field_dims) * args.embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, args.mlp_dims, args.dropout, output_layer=False)\n",
    "        self.fc = torch.nn.Linear(args.mlp_dims[-1] + args.embed_dim + args.cnn_latent_dim, 1)\n",
    "        \n",
    "        self.cnn = CNN_Base()\n",
    "\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        user_x = x[:, self.user_field_idx].squeeze(1)\n",
    "        item_x = x[:, self.item_field_idx].squeeze(1)\n",
    "        gmf = user_x * item_x\n",
    "        x = self.mlp(x.view(-1, self.embed_output_dim))\n",
    "        x = torch.cat([gmf, x], dim=1)\n",
    "        x = self.fc(x).squeeze(1)\n",
    "        return x\n",
    "    '''\n",
    "    \n",
    "    def forward(self, x):\n",
    "        user_isbn_vector, img_vector = x[0], x[1]\n",
    "        user_isbn_feature = self.embedding(user_isbn_vector)\n",
    "        \n",
    "        user_x = user_isbn_feature[:, self.user_field_idx].squeeze(1)\n",
    "        item_x = user_isbn_feature[:, self.item_field_idx].squeeze(1)\n",
    "        gmf = user_x * item_x\n",
    "        \n",
    "        mlp_x = self.mlp(user_isbn_feature.view(-1, self.embed_output_dim))\n",
    "        \n",
    "        img_feature = self.cnn(img_vector)\n",
    "        \n",
    "        x = torch.cat([gmf, mlp_x, img_feature], dim = 1)\n",
    "        x = self.fc(x).squeeze(1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- INIT CNN_NCF ---------------\n"
     ]
    }
   ],
   "source": [
    "######################## Model\n",
    "print(f'--------------- INIT {args.model} ---------------')\n",
    "model = CNN_NCF(args, data).to(args.device) #이부분수정하면됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RMSEloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.eps = 1e-6\n",
    "    def forward(self, x, y):\n",
    "        criterion = MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y)+self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:11<01:42, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_loss: 3.950, valid_loss: 2.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:22<01:30, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train_loss: 2.159, valid_loss: 2.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:33<01:18, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train_loss: 1.858, valid_loss: 2.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:44<01:06, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train_loss: 1.651, valid_loss: 2.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:56<00:55, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train_loss: 1.518, valid_loss: 2.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:07<00:44, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train_loss: 1.425, valid_loss: 2.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:18<00:33, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train_loss: 1.353, valid_loss: 2.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:30<00:22, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train_loss: 1.298, valid_loss: 2.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:41<00:11, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train_loss: 1.251, valid_loss: 2.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:52<00:00, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train_loss: 1.218, valid_loss: 2.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(args, model, dataloader, logger, setting):\n",
    "    minimum_loss = 999999999\n",
    "    if args.loss_fn == 'MSE':\n",
    "        loss_fn = MSELoss()\n",
    "    elif args.loss_fn == 'RMSE':\n",
    "        loss_fn = RMSELoss()\n",
    "    else:\n",
    "        pass\n",
    "    if args.optimizer == 'SGD':\n",
    "        optimizer = SGD(model.parameters(), lr=args.lr)\n",
    "    elif args.optimizer == 'ADAM':\n",
    "        optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(args.epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch = 0\n",
    "\n",
    "        for idx, data in enumerate(dataloader['train_dataloader']):\n",
    "            if args.model in ('CNN_FM', 'CNN_NCF'):\n",
    "                x, y = [data['user_isbn_vector'].to(args.device), data['img_vector'].to(args.device)], data['label'].to(args.device)\n",
    "            elif args.model == 'DeepCoNN':\n",
    "                x, y = [data['user_isbn_vector'].to(args.device), data['user_summary_merge_vector'].to(args.device), data['item_summary_vector'].to(args.device)], data['label'].to(args.device)\n",
    "            else:\n",
    "                x, y = data[0].to(args.device), data[1].to(args.device)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y.float(), y_hat)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            batch +=1\n",
    "        valid_loss = valid(args, model, dataloader, loss_fn)\n",
    "        print(f'Epoch: {epoch+1}, Train_loss: {total_loss/batch:.3f}, valid_loss: {valid_loss:.3f}')\n",
    "        logger.log(epoch=epoch+1, train_loss=total_loss/batch, valid_loss=valid_loss)\n",
    "        if minimum_loss > valid_loss:\n",
    "            minimum_loss = valid_loss\n",
    "            os.makedirs(args.saved_model_path, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f'{args.saved_model_path}/{setting.save_time}_{args.model}_model.pt')\n",
    "    logger.close()\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid(args, model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch = 0\n",
    "\n",
    "    for idx, data in enumerate(dataloader['valid_dataloader']):\n",
    "        if args.model in ('CNN_FM', 'CNN_NCF'):\n",
    "            x, y = [data['user_isbn_vector'].to(args.device), data['img_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        elif args.model == 'DeepCoNN':\n",
    "            x, y = [data['user_isbn_vector'].to(args.device), data['user_summary_merge_vector'].to(args.device), data['item_summary_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        else:\n",
    "            x, y = data[0].to(args.device), data[1].to(args.device)\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y.float(), y_hat)\n",
    "        total_loss += loss.item()\n",
    "        batch +=1\n",
    "    valid_loss = total_loss/batch\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "def test(args, model, dataloader, setting):\n",
    "    predicts = list()\n",
    "    if args.use_best_model == True:\n",
    "        model.load_state_dict(torch.load(f'./saved_models/{setting.save_time}_{args.model}_model.pt'))\n",
    "    else:\n",
    "        pass\n",
    "    model.eval()\n",
    "\n",
    "    for idx, data in enumerate(dataloader['test_dataloader']):\n",
    "        if args.model in ('CNN_FM', 'CNN_NCF'):\n",
    "            x, _ = [data['user_isbn_vector'].to(args.device), data['img_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        elif args.model == 'DeepCoNN':\n",
    "            x, _ = [data['user_isbn_vector'].to(args.device), data['user_summary_merge_vector'].to(args.device), data['item_summary_vector'].to(args.device)], data['label'].to(args.device)\n",
    "        else:\n",
    "            x = data[0].to(args.device)\n",
    "        y_hat = model(x)\n",
    "        predicts.extend(y_hat.tolist())\n",
    "    return predicts\n",
    "\n",
    "model = train(args, model, data, logger, setting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FM PREDICT ---------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######################## INFERENCE\n",
    "print(f'--------------- {args.model} PREDICT ---------------')\n",
    "predicts = test(args, model, data, setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- SAVE FM PREDICT ---------------\n"
     ]
    }
   ],
   "source": [
    "######################## SAVE PREDICT\n",
    "print(f'--------------- SAVE {args.model} PREDICT ---------------')\n",
    "submission = pd.read_csv(args.data_path + 'sample_submission.csv')\n",
    "if args.model in ('FM', 'FFM', 'NCF', 'WDN', 'DCN', 'CNN_FM', 'DeepCoNN'):\n",
    "    submission['rating'] = predicts\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답안 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = setting.get_submit_filename(args)\n",
    "submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
